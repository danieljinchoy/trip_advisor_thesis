html_node(".heading_title")%>%
html_text()
REview_Data <- rbind(REview_Data, data.frame(Restaurant_Name,id, quote,value_rating ,rating,date, review,count,things,Noofcontribution,Noofusefulvotes, stringsAsFactors = FALSE))
}
REview_Data
write.csv(REview_Data,"F:/R_Studio/Restaurant3.csv")
REview_Data
View(REview_Data)
url <- "https://www.tripadvisor.com/Attraction_Review-g303506-d1637149-Reviews-Favela_Tour-Rio_de_Janeiro_State_of_Rio_de_Janeiro.html#REVIEWS"
morepglist <-seq(10, 47, 10)
pickhotel <- url
# get list of urllinks corresponding to different pages
# url link for first search page
urllinkmain=pickhotel
# counter for additional pages
morepg=as.numeric(morepglist)
urllinkpre=paste(strsplit(urllinkmain,"Reviews-")[[1]][1],"Reviews",sep="")
urllinkpost=strsplit(urllinkmain,"Reviews-")[[1]][2]
urllink=rep(NA,length(morepg)+1)
urllink[1]=urllinkmain
for(i in 1:length(morepg)){
urllink[i+1]=paste(urllinkpre,"-or",morepg[i],"-",urllinkpost,sep="")
}
head(urllink)
REview_Data <- data.frame()
for (i in 1:30) {
reviews <- urllink[i] %>%
read_html() %>%
html_nodes("#REVIEWS .innerBubble")
usercount <- urllink[i] %>%
read_html() %>%
html_nodes("#REVIEWS .memberBadgingNoText")
id <- reviews %>%
html_node(".quote a") %>%
html_attr("id")
quote <- reviews %>%
html_node(".quote span") %>%
html_text()
value_rating <- reviews %>%
html_node("li .recommend-answer") %>%
html_attr("li") %>%
gsub("ui_bubble_rating bubble_40", "", .) %>%
gsub("0", "", .) %>%
as.integer()
rating <- reviews %>%
html_node(".rating span") %>%
html_attr("class") %>%
gsub("ui_bubble_rating bubble_", "", .) %>%
gsub("0", "", .) %>%
as.integer()
date <- reviews %>%
html_node(".rating .ratingDate") %>%
html_attr("title") %>%
strptime("%d %b %Y") %>%
as.POSIXct()
review <- reviews %>%
html_node(".entry .partial_entry") %>%
html_text()
webpage <- read_html(urllink[i])
count <- webpage %>%
html_node(".see_all_count") %>%
html_text()
things <- webpage %>%
html_node("span .header_popularity") %>%
html_text()
Noofcontribution <- usercount %>%
html_node(".badgetext") %>%
html_text()
Noofusefulvotes <- usercount %>%
html_node(".badgetext:last-child") %>%
html_text()
Restaurant_Name<-webpage%>%
html_node(".heading_title")%>%
html_text()
REview_Data <- rbind(REview_Data, data.frame(Restaurant_Name,id, quote,value_rating ,rating,date, review,count,things,Noofcontribution,Noofusefulvotes, stringsAsFactors = FALSE))
}
REview_Data
View(REview_Data)
View(REview_Data)
url <- "https://www.tripadvisor.com/Attraction_Review-g303506-d1637149-Reviews-Favela_Tour-Rio_de_Janeiro_State_of_Rio_de_Janeiro.html#REVIEWS"
morepglist <-seq(10, 470, 10)
pickhotel <- url
# get list of urllinks corresponding to different pages
# url link for first search page
urllinkmain=pickhotel
# counter for additional pages
morepg=as.numeric(morepglist)
urllinkpre=paste(strsplit(urllinkmain,"Reviews-")[[1]][1],"Reviews",sep="")
urllinkpost=strsplit(urllinkmain,"Reviews-")[[1]][2]
urllink=rep(NA,length(morepg)+1)
urllink[1]=urllinkmain
for(i in 1:length(morepg)){
urllink[i+1]=paste(urllinkpre,"-or",morepg[i],"-",urllinkpost,sep="")
}
head(urllink)
REview_Data <- data.frame()
for (i in 1:30) {
reviews <- urllink[i] %>%
read_html() %>%
html_nodes("#REVIEWS .innerBubble")
usercount <- urllink[i] %>%
read_html() %>%
html_nodes("#REVIEWS .memberBadgingNoText")
id <- reviews %>%
html_node(".quote a") %>%
html_attr("id")
quote <- reviews %>%
html_node(".quote span") %>%
html_text()
value_rating <- reviews %>%
html_node("li .recommend-answer") %>%
html_attr("li") %>%
gsub("ui_bubble_rating bubble_40", "", .) %>%
gsub("0", "", .) %>%
as.integer()
rating <- reviews %>%
html_node(".rating span") %>%
html_attr("class") %>%
gsub("ui_bubble_rating bubble_", "", .) %>%
gsub("0", "", .) %>%
as.integer()
date <- reviews %>%
html_node(".rating .ratingDate") %>%
html_attr("title") %>%
strptime("%d %b %Y") %>%
as.POSIXct()
review <- reviews %>%
html_node(".entry .partial_entry") %>%
html_text()
webpage <- read_html(urllink[i])
count <- webpage %>%
html_node(".see_all_count") %>%
html_text()
things <- webpage %>%
html_node("span .header_popularity") %>%
html_text()
Noofcontribution <- usercount %>%
html_node(".badgetext") %>%
html_text()
Noofusefulvotes <- usercount %>%
html_node(".badgetext:last-child") %>%
html_text()
Restaurant_Name<-webpage%>%
html_node(".heading_title")%>%
html_text()
REview_Data <- rbind(REview_Data, data.frame(Restaurant_Name,id, quote,value_rating ,rating,date, review,count,things,Noofcontribution,Noofusefulvotes, stringsAsFactors = FALSE))
}
REview_Data
View(REview_Data)
write.table(REview_Data, file = "/favela.csv", sep = ",", col.names = NA,
qmethod = "double")
write.csv(REview_Data,'favela.csv')
library(dplyr)
install.packages("tidytext")
library(tidytext)
R.Version()
install.packages("tidytext
library(tidytext)
text_df %>%
unnest_tokens
d
sdfsdf
4
library(dplyr)
View(REview_Data)
View(REview_Data)
View(REview_Data)
text_df %>%
unnest_tokens(word, review)
library(dplyr)
library(tidytext)
text_df %>%
unnest_tokens(word, review)
text_df <- REview_Data(line = 1:297, test = review)
install.packages(c("rJava", "wordcloud", "textir", "RWeka", "qdap", "maptpx"))
# Load library
library(tm)
library(stringr)
library(rvest)
library(xml2)
library(NLP)
library(rvest)
# Load library
library(tm)
library(stringr)
# Web scraping live reviews of JW Marriott hotel from Trip-Advisor
df <- data.frame(Date=as.Date(character()), File=character(), User=character(), stringsAsFactors=FALSE)
x <- 0
for(i in c(1:100)){
url <- ""
if(x == 0){
url <- "http://www.tripadvisor.com/Hotel_Review-g37209-d1762915-Reviews-JW_Marriott_Indianapolis-Indianapolis_Indiana.html"
x <- x + 10
} else{
url <- paste("https://www.tripadvisor.com/Hotel_Review-g37209-d1762915-Reviews-or",x,"-JW_Marriott_Indianapolis-Indianapolis_Indiana.html#REVIEWS", sep = "")
x <- x + 10
}
reviews <- url %>%
read_html() %>%
html_nodes("#REVIEWS .innerBubble")
id <- reviews %>%
html_node(".quote a") %>%
html_attr("id")
review <- reviews %>%
html_node(".entry .partial_entry") %>%
html_text()
if(nrow(df) == 0){
df <- data.frame(id, review, stringsAsFactors = FALSE)
}
else{
temp <- df
df <- rbind(temp, data.frame(id, review, stringsAsFactors = FALSE))
}
}
# Write the dataframe to a csv
write.csv(df, "tripadvisor_reviews.csv")
# Write the dataframe to a csv
write.csv(df, "tripadvisor_reviews.csv")
# Load the same csv
trip <- read.csv("tripadvisor_reviews.csv")
hotel_reviews <- as.character(trip$review)
# Load the positive and negative lexicon data and explore
positive_lexicon <- read.csv("positive-lexicon.txt")
negative_lexicon <- read.csv("negative-lexicon.txt")
# Making a corpus out of the hotel reviews
reviews_corpus <- Corpus(VectorSource(hotel_reviews))
inspect(reviews_corpus)
# Remove stop words, punctuations, numbers from all the reviews and inspecting it
filtered_corpus_no_stopwords <- tm_map(reviews_corpus, removeWords, stopwords('english'))
inspect(filtered_corpus_no_stopwords)
filtered_corpus_no_puncts <- tm_map(filtered_corpus_no_stopwords, removePunctuation)
inspect(filtered_corpus_no_puncts)
filtered_corpus_no_numbers <- tm_map(filtered_corpus_no_puncts, removeNumbers)
inspect(filtered_corpus_no_numbers)
filtered_corpus_no_whitespace <- tm_map(filtered_corpus_no_numbers, stripWhitespace)
inspect(filtered_corpus_no_whitespace)
filtered_corpus_to_lower <- tm_map(filtered_corpus_no_whitespace, content_transformer(tolower))
inspect(filtered_corpus_to_lower)
# Load the stop words text file and explore
stop_words <- read.csv("stopwords_en.txt")
# Load the stop words text file and explore
stop_words <- read.csv("stopwords_en.txt")
# Remove stop words of the external file from the corpus and whitespaces again and inspect
stopwords_vec <- as.data.frame(stop_words)
final_corpus_no_stopwords <- tm_map(filtered_corpus_to_lower, removeWords, stopwords_vec[,1])
inspect(final_corpus_no_stopwords)
final_corpus <- tm_map(final_corpus_no_stopwords, stripWhitespace)
final_corpus_no_stopwords <- tm_map(filtered_corpus_to_lower, removeWords, stopwords_vec[,1])
inspect(final_corpus)
# Character representation of the corpus of first review
final_corpus[[1]]$content
hotel_reviews[1]
# Stem the words to their root of all reviews present in the corpus
stemmed_corpus <- tm_map(final_corpus, stemDocument)
# Building a term document matrix of the stemmed corpus
TDM_corpus <- TermDocumentMatrix(stemmed_corpus)
findFreqTerms(TDM_corpus, 5)                    # terms occurring with a minimum frequency of 5
# Calculating the count and percentage of total positive and negative words in each review and
# Labeling each review as either negative or positive
total_pos_count <- 0
total_neg_count <- 0
pos_count_vector <- c()
neg_count_vector <- c()
size <- length(stemmed_corpus)
for(i in 1:size){
corpus_words<- list(strsplit(stemmed_corpus[[i]]$content, split = " "))
#print(intersect(unlist(corpus_words), unlist(positive_lexicon))) ## positive words in current review
pos_count <- length(intersect(unlist(corpus_words), unlist(positive_lexicon)))
#print(intersect(unlist(corpus_words), unlist(negative_lexicon))) ## negative words in current review
neg_count <- length(intersect(unlist(corpus_words), unlist(negative_lexicon)))
if(pos_count>neg_count){
#print("It's a positive review")
} else{
#print("It's a negative review")
}
total_count_for_current_review <- pos_count + neg_count ## current positive and negative count
pos_percentage <- (pos_count*100)/total_count_for_current_review
neg_percentage <- (neg_count*100)/total_count_for_current_review
#print(pos_percentage)                          ## current positive percentage
#print(neg_percentage)                          ## current negtive percentage
total_pos_count <- total_pos_count + pos_count ## overall positive count
total_neg_count <- total_neg_count + neg_count ## overall negative count
pos_count_vector <- append(pos_count_vector, pos_count)
neg_count_vector <- append(neg_count_vector, neg_count)
}
# Sentiment score of each review and visualizing using boxplot
counts <- data.frame(pos_count_vector, neg_count_vector)
sentiment <- data.frame(c(1:size),(pos_count_vector - neg_count_vector) / (pos_count_vector + neg_count_vector))
boxplot(sentiment$X.pos_count_vector...neg_count_vector...pos_count_vector...neg_count_vector.[0:100]~sentiment$c.1.size.[0:100])
sentiment <- data.frame(c(1:size),(pos_count_vector - neg_count_vector) / (pos_count_vector + neg_count_vector))
library(tidytext)
favela <- REview_Data
favela %>%
unnest_tokens(word, review)
read.csv("/favela2.csv")
favela <- read.csv("/favela2.csv")
getwd()
favela <- read.csv("/Users/danielchoy/Desktop/Tripadvisor/comps/favela2.csv")
favela %>%
unnest_tokens(word, review)
View(favela)
favela <- read.csv("/Users/danielchoy/Desktop/Tripadvisor/comps/favela2.csv")
favela <- REview_Data
favela <- read.csv("/Users/danielchoy/Desktop/Tripadvisor/comps/favela2.csv")
favela %>%
unnest_tokens(word, review)
favela <- REview_Data
favela %>%
unnest_tokens(word, review)
tidy_favela <- favela %>%
unnest_tokens(word, review)
View(tidy_favela)
tidy_favela <- tidy_favela %>%
anti_join(stop_words)
?anti_join
tidy_favela2 <- tidy_favela %>%
anti_join(stop_words)
tidy_favela2 <- tidy_favela %>%
anti_join(stop_words, by=c("text"="word"))
stop_words
tidy_favela2 <- tidy_favela %>%
anti_join(stop_words, by=c("word"="word"))
tidy_favela <- tidy_favela %>%
anti_join(stop_words, by=c("word"="word"))
tidy_favela <- tidy_favela %>%
filter(!word %in% stop_words$word)
View(tidy_favela)
favela <- read.csv("/Users/danielchoy/Desktop/Tripadvisor/comps/favela2.csv")
tidy_favela <- favela %>%
unnest_tokens(new_review, review)
tidy_favela <- tidy_favela %>%
anti_join(stop_words, by=c("new_review"="word"))
favela <- REview_Data
tidy_favela <- favela %>%
unnest_tokens(new_review, review)
tidy_favela <- tidy_favela %>%
anti_join(stop_words, by=c("new_review"="word"))
view(stop_words)
View(stop_words)
tidy_favela
tidy_favela <- tidy_favela %>%
anti_join(stop_words, by=c("new_review"="word"))
tidy_favela <- tidy_favela %>%
filter(!new_review %in% stop_words$word)
View(tidy_favela)
stop_words
tidy_favela <- tidy_favela %>%
filter(!new_review %in% stop_words$word)
View(tidy_favela)
tidy_favela <- tidy_favela %>%
anti_join(stop_words, by=c("new_review"="word"))
favela <- REview_Data
tidy_favela <- favela %>%
unnest_tokens(new_review, review) %/%
anti_join(stop_words)
Web scraping live reviews of JW Marriott hotel from Trip-Advisor
df <- data.frame(Date=as.Date(character()), File=character(), User=character(), stringsAsFactors=FALSE)
x <- 0
for(i in c(1:100)){
url <- ""
if(x == 0){
url <- "http://www.tripadvisor.com/Hotel_Review-g37209-d1762915-Reviews-JW_Marriott_Indianapolis-Indianapolis_Indiana.html"
x <- x + 10
} else{
url <- paste("https://www.tripadvisor.com/Hotel_Review-g37209-d1762915-Reviews-or",x,"-JW_Marriott_Indianapolis-Indianapolis_Indiana.html#REVIEWS", sep = "")
x <- x + 10
}
reviews <- url %>%
read_html() %>%
html_nodes("#REVIEWS .innerBubble")
id <- reviews %>%
html_node(".quote a") %>%
html_attr("id")
review <- reviews %>%
html_node(".entry .partial_entry") %>%
html_text()
if(nrow(df) == 0){
df <- data.frame(id, review, stringsAsFactors = FALSE)
}
else{
temp <- df
df <- rbind(temp, data.frame(id, review, stringsAsFactors = FALSE))
}
}
# Write the dataframe to a csv
write.csv(df, "tripadvisor_reviews.csv")
# Sentiment Analysis of Hotel Reviews on Trip Advisor
# Load the same csv
trip <- read.csv("tripadvisor_reviews.csv")
hotel_reviews <- as.character(trip$review)
# Load the positive and negative lexicon data and explore
positive_lexicon <- read.csv("positive-lexicon.txt")
negative_lexicon <- read.csv("negative-lexicon.txt")
# Making a corpus out of the hotel reviews
reviews_corpus <- Corpus(VectorSource(hotel_reviews))
inspect(reviews_corpus)
# Remove stop words, punctuations, numbers from all the reviews and inspecting it
filtered_corpus_no_stopwords <- tm_map(reviews_corpus, removeWords, stopwords('english'))
inspect(filtered_corpus_no_stopwords)
filtered_corpus_no_puncts <- tm_map(filtered_corpus_no_stopwords, removePunctuation)
inspect(filtered_corpus_no_puncts)
filtered_corpus_no_numbers <- tm_map(filtered_corpus_no_puncts, removeNumbers)
inspect(filtered_corpus_no_numbers)
filtered_corpus_no_whitespace <- tm_map(filtered_corpus_no_numbers, stripWhitespace)
inspect(filtered_corpus_no_whitespace)
filtered_corpus_to_lower <- tm_map(filtered_corpus_no_whitespace, content_transformer(tolower))
inspect(filtered_corpus_to_lower)
# Write the dataframe to a csv
write.csv(df, "tripadvisor_reviews.csv")
# Load the same csv
trip <- read.csv("tripadvisor_reviews.csv")
hotel_reviews <- as.character(trip$review)
# Load the positive and negative lexicon data and explore
positive_lexicon <- read.csv("positive-lexicon.txt")
negative_lexicon <- read.csv("negative-lexicon.txt")
# Making a corpus out of the hotel reviews
reviews_corpus <- Corpus(VectorSource(hotel_reviews))
inspect(reviews_corpus)
View(trip)
tidy_favela <- favela %>%
unnest_tokens(new_review, review) %/%
anti_join(stop_words)
favela <- REview_Data
xtidy_favela <- tidy_favela %>%
anti_join(stop_words, by=c("new_review"="word"))
library(dplyr)
library(tidytext)
tidy_favela <- favela %>%
unnest_tokens(new_review, review) %/%
anti_join(stop_words)
tidy_favela <- tidy_favela %>%
anti_join(stop_words, by=c("new_review"="word"))
tidy_favela <- tidy_favela %>%
filter(!new_review %in% stop_words$word)
View(tidy_favela)
View(stop_words)
View(REview_Data)
favela <- read.csv("favela.csv", header = TRUE)
corpus <- Courpus(VectorSource(favela$review))
corpus <- Corpus(VectorSource(favela$review))
corpus <- corpus(VectorSource(favela$review))
library(tmap)
library(tm)
install.packages("tm", repos="http://R-Forge.R-project.org")
install.packages("tm", repos = "http://R-Forge.R-project.org")
y
library(tm)
install.packages("slam")
library(slam)
install.packages("tm", repos="http://R-Forge.R-project.org")
favela <- read.csv("favela.csv", header = TRUE)
corpus <- Corpus(VectorSource(favela$review))
library(tm)
corpus <- Corpus(VectorSource(favela$review))
View(corpus)
# convert the text to lower case
corpus <- tm_map(corpus, content_transformer(tolower))
# remove numbers
corpus <- tm_map(corpus, removeNumbers)
# remove english common stopwords
corpus <- tm_map(corpus, removeWords( stopwords("english")))
View(favela)
corpus <- Corpus(VectorSource(favela$review))
corpus[[1]][1]
# convert the text to lower case
corpus <- tm_map(corpus, content_transformer(tolower))
# remove numbers
corpus <- tm_map(corpus, removeNumbers)
# remove english common stopwords
corpus <- tm_map(corpus, removeWords( stopwords("english")))
# remove english common stopwords
corpus <- tm_map(corpus, removeWords( stopwords("english")))
# remove english common stopwords
corpus <- tm_map(corpus, removeWords(stopwords("english")))
# remove punctuations
corpus <- tm_map(corpus, removePunctuation)
# elimniate extra white spaces
corpus <- tm_map(corpus, stripWhitespace)
# create TDM
tdm <- TermDocumentMatrix(corpus)
m <- as.matrix(tdm)
v <- sort(rowSums(m), decreasing = TRUE)
d <- data.frame(word = names(v), freq = v)
wordcloud((d$word, d$freq, random.order = FALSE, rot.per = 0.3, scale = c(4, .5), max.words = 1-1, colors = brewer.pal(8, "Dark2"))
wordcloud((d$word, d$freq, random.order = FALSE, rot.per = 0.3, scale = c(4, .5), max.words = 1-1, colors = brewer.pal(8, "Dark2")))
library(wordcloud)
library(RColorBrewer)
wordcloud((d$word, d$freq, random.order = FALSE, rot.per = 0.3, scale = c(4, .5), max.words = 1-1, colors = brewer.pal(8, "Dark2"))
wordcloud((d$word, d$freq, random.order = FALSE, rot.per = 0.3, scale = c(4, .5), max.words = 101, colors = brewer.pal(8, "Dark2"))
wordcloud((d$word, d$freq, random.order = FALSE, rot.per = 0.3, scale = c(4, .5), max.words = 101, colors = brewer.pal(8, "Dark2")))
wordcloud((d$word, d$freq, random.order = FALSE, rot.per = 0.3, scale = c(4, .5), max.words = 101, colors = brewer.pal(8, "Dark2")))
tidy_favela <- tidy_favela %>%
anti_join(tidytext$stop_words, by=c("new_review"="word"))
tidy_favela <- tidy_favela %>%
anti_join(stop_words, by=c("new_review"="word"))
library(tidytext)
search(stop_words)
tidy_favela <- tidy_favela %>%
anti_join(stopwords, by=c("new_review"="word"))
library(dplyr)
favela <- REview_Data
tidy_favela <- tidy_favela %>%
anti_join(stopwords, by=c("new_review"="word"))
tidy_favela <- favela %>%
unnest_tokens(new_review, review) %/%
anti_join(stop_words)
tidy_favela <- tidy_favela %>%
filter(!new_review %in% stop_words$word)
View(tidy_favela)
tidy_favela <- tidy_favela %>%
anti_join(stopwords, by=c("new_review"="word"))
View(favela)
